**参考资料**
[一文带你 "看见" MCP 的过程，彻底理解 MCP 的概念-阿里云开发者社区](https://developer.aliyun.com/article/1665090)
[MCP Server的五种主流架构与Nacos的选择-阿里云开发者社区](https://developer.aliyun.com/article/1665101?scm=20140722.ID_community%40%40article%40%401665101._.ID_community%40%40article%40%401665101-OR_rec-PAR1_0be3e0cb17532512608606478e7cb1-V_1-RL_community%40%40article%40%401665090#slide-5)


## 简介
本文主要介绍了模型上下文协议的基本概念。**MCP是一种连接AI助手和数据系统的开放标准，旨在帮助大模型生成更高质量的响应。**

## 理论背景

为了让大模型能够生成更好的响应，在MCP出现之前，学界和商界已经进行了多种技术实践，比较具有代表性的就是RAG技术和Function Calling。RAG是为了让模型获得足够多的上下文，以保证大模型在垂直知识领域中避免幻觉问题，Function Calling则能让大模型调用工具。

#### RAG

RAG（Retrieve Augmented Generation， 检索增强生成）。该技术主要用于大模型在垂直细分的知识领域中的应用。在不应用RAG的情况下，大模型在垂直领域上存在幻觉，必须经过微调来对齐专业知识。RAG技术即根据用户的问题，从向量数据库中提取出top K个高度相似的片段，拼接到问题中再发给大模型，大模型结合专业知识可以做到更好地回答问题。

这就意味着，在使用RAG之前，需要将资料通过嵌入模型进行词嵌入，从而将其转化成词向量，最终储存在向量数据库中提供查询。
![[Pasted image 20250723141425.png]]

#### Function Calling

Function Calling（函数调用）是一种允许大语言模型根据用户的输入，识别出完成任务需要的工具以及使用工具的时机的一种机制。

工作原理：LLM 接收用户的提示词，LLM 决定它需要的工具，执行方法调用，后端服务执行实际的请求给出处理结果，大语言模型根据处理结果生成最终给用户的回答。
![[Pasted image 20250723141604.png]]

#### MCP

MCP（Model Context Protocol， 模型上下文协议）是一个由Anthropic在2024年提出的新标准。其是一个开放标准，旨在连接AI助手与数据库所在的系统，包括内容存储库、业务工具和开发环境。目标是让大语言模型产生更高质量的响应。

![[Pasted image 20250723141830.png]]

#####  MCP的核心部件

MCP遵循客户端-服务器架构，主机中挂载多个客户端，可以连接到多个服务器。
相关组件：
- 主机（Host）
- 客户端（Client）
- 服务器（Server）

**主机**：表示任何提供AI交互环境的应用程序（例如Claude、 Cursor），其可以访问工具和数据，并挂载运行MCP Client。

**MCP客户端**：在主机内进行，其的作用是与MCP Server连接通信。

**MCP服务器**：向外暴露特定功能并提供数据访问，例如：
- 工具（Tool）：使LLM能通过服务器进行操作
- 资源（Resource）：使LLM能够公开服务器中的数据和内容
- 提示（Prompt）：创建可重用的提示模板和工作流

##### MCP的核心流程步骤
![[Pasted image 20250723144731.png]]
1. 用户发起请求（①）
	- 用户输入自然语言查询。
2. MCP客户端处理（②-④）
	- MCP客户端将查询发送给MCP主机。
	- MCP主机将查询传递给LLM。
	- LLM分析查询，给出要调用的工具，生成结构化工具请求。
3. 工具调用执行（⑤-⑦）
	- MCP主机将工具请求发送给MCP服务器。
	- MCP服务器调用指定工具。
	- 工具返回结构化的结果
4. 结果响应整合（⑧-⑩）
	- 服务器将结构化相应返回MCP主机。
	- 主机将原始查询+工具输出一起发送给LLM。
	- LLM结合上下文生成最终相应，并返回给用户。
