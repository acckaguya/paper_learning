# 分布式计算-数据并行

参考资料：
[大模型分布式训练并行技术（一）-概述 - 知乎](https://zhuanlan.zhihu.com/p/598714869)
[PyTorch数据并行怎么实现？DP、DDP、FSDP数据并行原理？【分布式并行】系列第02篇_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1JK411S7gL?spm_id_from=333.788.videopod.sections&vd_source=e3f840dae549a0bdcc08b0ec98f731eb)
### 简述
数据并行的思路如下：将大的数据集分成N份，将每一份分别装载到N个不同的GPU上训练。同时每个GPU上都有一个完整的模型。计算完成后，N个GPU返回N个结果，在GPU0中进行梯度累加并更新参数。最后将更新后的参数广播至N个GPU节点中。

![[Pasted image 20250722231214.png]]
除了使用GPU0作为参数服务器外，还会使用CPU作为参数服务器，但是效率会降低。

还可以将参数服务器分布在所有的GPU节点上，每个GPU只更新其中的一部分梯度。
![[Pasted image 20250722231409.png]]

### Pytorch DP
数据并行(torch.nn.DataParallel)，是Pytorch上提供的一种数据并行方式，基于单进程多线程实现，受限于GIL，性能开销大且效率不高。

计算过程如下：
- 将 inputs 从主 GPU 分发到所有 GPU 上。
- 将 model 从主 GPU 分发到所有 GPU 上。
- 每个 GPU 分别独立进行前向传播，得到 outputs。
- 将每个 GPU 的 outputs 发回主 GPU。
- 在主 GPU 上，通过 loss function 计算出 loss，对 loss function 求导，求出损失梯度。
- 计算得到的梯度分发到所有 GPU 上。
- 反向传播计算参数梯度。
- 将所有梯度回传到主 GPU，通过梯度更新模型权重。
- 不断重复上面的过程。
![[Pasted image 20250722231651.png]]

该方法的缺点：
- 单进程多线程带来的问题：受困于GIL，性能开销大，训练效率低，只支持单机多卡，无法使用多服务器进行训练，无法使用Apex进行混合精度训练。
- 参数服务器的性能以及通信开销容易成为瓶颈，GPU的利用率很低。
- 不支持模型并行。

### 分布式数据并行（Pytorch DDP）
分布式数据并行(torch.nn.DistributedDataPrallel)，是基于多线程实现的数据并行方式。每一个进程有自己的优化器，执行自己的更新过程。每个进程执行相同任务，并且每个进程都与其他的进程通信。GPU之间值传递梯度。
![[Pasted image 20250722232223.png]]

DDP具体流程如下：
- 首先将 rank=0 进程中的模型参数广播到进程组中的其他进程；
- 然后，每个 DDP 进程都会创建一个 **local Reducer** 来负责梯度同步。
- 在训练过程中，每个进程从磁盘加载 batch 数据，并将它们传递到其 GPU。每个 GPU 都有自己的前向过程，完成前向传播后，**梯度在各个 GPUs 间进行 All-Reduce**，每个 GPU 都收到其他 GPU 的梯度，从而可以独自进行反向传播和参数更新。
- 同时，每一层的梯度不依赖于前一层，所以**梯度的 All-Reduce 和后向过程同时计算**，以进一步缓解网络瓶颈。
- 在后向过程的最后，每个节点都得到了平均梯度，这样各个 GPU 中的模型参数保持同步 。

在DDP中，梯度是被广播到所有的GPU中，相较于DP将所有梯度都reduce到参数服务器GPU0的方式，DDP能更好地进行负载均衡，提高了多机多卡运算的能力。

**DDP和DP的不同**:
- 实现方法不同：DP使用单进程多线程的方式实现分布式计算；DDP使用多进程的方式实现分布式计算。
- 参数更新的方式不同：DP是各GPU将前向传播的结果reduce至GPU0，由GPU计算loss、梯度并更新参数，将最后的参数广播至所有的GPU；DDP的方式为各GPU广播计算好的梯度，各GPU收到所有梯度后，进行平均，最后在本GPU上更新自己的参数。


**通信原语**

| ​**操作**​             | ​**功能**​                                 | ​**与AllReduce的区别**​                    |
| -------------------- | ---------------------------------------- | -------------------------------------- |
| ​**Reduce**​         | 聚合数据到单一节点                                | 结果仅存于主节点，不广播                           |
| ​**Broadcast**​      | 主节点向所有节点分发数据                             | 仅单向分发，无聚合操作                            |
| ​**AllGather**​      | 所有节点收集完整数据（如 [10,20,30,40] → 所有节点获得全量数据） | 无归约运算，仅数据聚合                            |
| ​**Reduce-Scatter**​ | 先归约再分块分发（如梯度按层分片）                        | AllReduce = Reduce-Scatter + AllGather |
![[Pasted image 20250723100242.png]]
### 完全分片数据并行（Pytorch FSDP）
完全分片数据并行(torch.distributed.fsdp.FullySharedDataParallel)，是一种数据并行方案。在DDP中，每个GPU要完整地维护整个模型的信息（模型参数、优化器状态、梯度等）。FSDP将这些跨状态的数据在工作线程上进行分片，并且支持将模型参数卸载到CPU。

FSDP的工作流程：
![[Pasted image 20250723103038.png]]

FSDP的要点为，将All Reduce过程拆解成了Reduce-Scatter 和 All-Gather两个过程:
- Reduce-Scatter阶段：在每个GPU上会基于rank索引对rank之间相等的块进行求和。
- All-Gather阶段：每个GPU上的聚合梯度分片可供所有GPU使用。
通过这两个过程，每一个GPU（DDP worker）只需要存储一个参数分片和优化器状态。

**DDP和FSDP的区别**
![[Pasted image 20250723103527.png]]

FSDP的工作流程：
- **Model shard**：每个GPU上仅存在**模型的分片**。
- **All-gather**：每个GPU通过all-gather从其他GPU收集所有**权重**，以在本地计算前向传播。
- **Forward（local）**：在本地进行前向操作。前向计算和后向计算都是利用完整模型。
- **All-gather**：然后在后向传播之前再次执行此**权重**收集。
- **Backward（local）**：本地进行后向操作。前向计算和后向计算都是利用完整模型，此时每个GPU上也都是**全部梯度**。
- **Reduce-Scatter**：在向后传播之后，局部**梯度**被聚合并且通过 Reduce-Scatter 在各个GPU上分片，每个分片上的梯度是聚合之后本分片对应的那部分。
- **Update Weight（local）**：每个GPU更新其局部**权重**分片。

### 总结
本博客主要讲述了分布式训练中三种常见的数据并行技术（DP、DDP和FSDP）。

DP存在锁机制，以及通信存在瓶颈，引入了DDP技术，通过多线程技术和GPU之间直接广播梯度，缓解了DP中参数服务器的性能瓶颈问题。FSDP通过将模型的各种状态数据进行分片的方式，极大提高了内存效率/